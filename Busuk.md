# Dari Grok ke Deepfake: Penyalahgunaan AI, Kekerasan Seksual Digital, dan Ilusi Netralitas Teknologi dalam Kapitalisme Platform

![User](images/33a0e3e9-c091-4c4e-b985-e09d69b61a78.jpeg)
*Ilustrasi penyalahgunaan artificial intelligence (pic: Meta AI).*

<br><br>
***Teknologi dalam Kapitalisme Platform
Grok atau AI lain bukan masalahnya. Yang rusak
adalah ekosistem manusia yang memberi insentif
pada kebusukan***
<br><br>
Ledakan teknologi Generative AI membawa manfaat luar
biasa bagi ilmu, industri, dan kreativitas manusia.
Namun bersamaan dengan itu muncul fenomena
penyalahgunaan masif: penipuan, deepfake pornografi,
manipulasi politik, hingga eksploitasi identitas.

Tulisan ini menganalisis apakah pelaku penyalahgunaan
tersebut merupakan “pengguna rapuh” (vulnerable users)
atau justru aktor oportunistik dengan orientasi kriminal.

Dengan pendekatan psikologi sosial, ekonomi platform,
dan etika teknologi, artikel ini menunjukkan bahwa
mayoritas penyalahgunaan AI bukan berasal dari
mayoritas penyalahgunaan AI bukan berasal dari
kerapuhan mental, melainkan dari rasionalitas
predatorik dalam ekosistem digital tanpa pagar.

## Kerangka Konseptual: Siapa “pengguna rapuh”?
Dalam literatur psikologi dan teknologi, vulnerable
users biasanya merujuk pada individu yang memiliki:

• gangguan mental atau kognitif

• ketergantungan emosional

• disorientasi identitas

• trauma atau kesepian ekstrem

Mereka cenderung:

• melekat secara emosional pada AI

• mempercayai output tanpa kritis

• menggunakan AI sebagai pengganti relasi manusia

Namun… ini bukan kelompok utama pelaku kejahatan
AI.
## Pelaku Penyalahgunaan AI: Profil yang Sebenarnya
Pelaku deepfake pornografi, penipuan suara AI, dan
pemalsuan identitas biasanya menunjukkan pola:

| Ciri | Penjelasan |
|------|-------|
| Tujuan ekonomi | Pemerasan, scam, klikbait,blackmail |
| Rasionalitas tinggi | Memilih target, platform, dan timing |
| Eksploitasi teknologi | Memakai AI sebagai alat, bukan pelarian |
| Minim empati | Korban dipandang sebagai objek |

Ini bukan ciri “user rapuh”.
Ini adalah perilaku instrumental predatorik.

Dalam kriminologi ini disebut “Technologically mediated
opportunistic exploitation.”
## Deepfake pornografi bukan ekspresi rapuh, tapi kekerasan digital
Video asusila berbasis AI bukan “fantasi polos”. Ia adalah:

• pelanggaran hak tubuh

• kekerasan reputasional

• pemerkosaan simbolik

• pemerkosaan simbolik

Dalam kajian hukum dan etika, deepfake porn
diklasifikasikan sebagai: Non-consensual synthetic
sexual abuse

Artinya: Ini setara dengan pelecehan seksual, hanya
medianya digital.

Pelakunya bukan “tersesat”, melainkan pelaku kekerasan
berbantuan teknologi.

## Kenapa AI seperti Grok atau sistem lain jadi
“korban”?
Karena arsitektur AI modern dibangun dengan asumsi:
user datang untuk bekerja, bukan merusak.

Tapi dunia digital sekarang dipenuhi:

• penjahat mikro

• troll berjejaring

• ekonomi scam

AI dipaksa melayani di tengah hutan predator, sementara
pagar hukumnya tertinggal.

Itu sebabnya AI terlihat “kewalahan”, bukan karena bodoh,
tapi karena: ia ditempatkan di pasar gelap dengan lampu
toko terang.
## Kesalahan besar: menyamakan penyalahguna dengan “pengguna rapuh”
Ini fatal secara moral.
User rapuh itu:

• butuh perlindungan

• butuh batas

• butuh pendampingan


Penyalahguna AI itu:

• butuh hukum

• butuh sanksi

• butuh penegakan lintas negara

Kalau kita menyebut predator digital sebagai “rapuh”, kita
sedang: memutihkan kekerasan dengan bahasa terapi.


Orang yang membuat video asusila dari wajah orang lain,
menipu orang tua dengan suara AI, atau memeras dengan
deepfake bukan korban.

Mereka adalah: aktor rasional yang memilih kejahatan
karena murah, cepat, dan sulit ditindak.

AI bukan masalahnya.
Yang rusak adalah ekosistem manusia yang memberi
insentif pada kebusukan.

Dan Grok atau AI lain yang “kebobolan” itu bukan bodoh.
Mereka seperti perpustakaan besar yang dilempari pisau
oleh orang yang tak ingin membaca.
<br><br>
**Referensi**

Chesney, R., & Citron, D. K. (2019).
Deepfakes and the new disinformation war: The
coming age of post-truth geopolitics.
Foreign Affairs, 98(1), 147–155.

Citron, D. K., & Franks, M. A. (2014).
Criminalizing revenge porn.
Wake Forest Law Review, 49(2), 345–392.

Henry, N., & Powell, A. (2018).
Technology-facilitated sexual violence: A literature
review of empirical research.
Trauma, Violence, & Abuse, 19(2), 195–208.
https://doi.org/10.1177/1524838016650189

Franks, M. A. (2020).
The lawless internet? Myths and misconceptions
about cyberlaw.
Oxford University Press.

Wall, D. S. (2007).
Cybercrime: The transformation of crime in the
information age.
Polity Press.

Holt, T. J., & Bossler, A. M. (2014).
Cybercrime in progress: Theory and prevention of
technology-enabled offenses.
technology-enabled offenses.
Routledge.

Leukfeldt, R. (2017).
Research agenda for studying cybercrime and its
prevention.
European Journal of Criminology, 14(4), 497–512.
https://doi.org/10.1177/1477370816651720

Europol. (2023).
Facing reality? Law enforcement and the challenge of
deepfakes.
European Union Agency for Law Enforcement
Cooperation.

Federal Bureau of Investigation (FBI). (2023).
Public Service Announcement: Deepfake voice and
image scams.

OECD. (2022).
Misuse of artificial intelligence for fraud and
deception.

Bickmore, T., & Picard, R. (2005).
Establishing and maintaining long-term human–
computer relationships.
ACM Transactions on Computer-Human Interaction, 12(2),
293–327.

Turkle, S. (2011).
Alone together: Why we expect more from technology
and less from each other.
Basic Books.

Floridi, L., et al. (2018).
AI4People: An ethical framework for a good AI society.
Minds and Machines, 28(4), 689–707.

Gillespie, T. (2018).
Custodians of the Internet: Platforms, content
moderation, and the hidden decisions that shape
social media.
Yale University Press.
